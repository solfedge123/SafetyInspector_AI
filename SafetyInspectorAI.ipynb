{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "safety-inspectorAI/\n",
        "\n",
        "*   ├── app.py                 # Main Gradio application\n",
        "├── requirements.txt       # Python dependencies\n",
        "├── train_autoencoder.py   # Unsupervised training\n",
        "├── detect_anomaly.py      # Anomaly detection logic\n",
        "├── detect_helmet.py       # YOLOv8 helmet detection\n",
        "├── models/\n",
        "│   ├── autoencoder.pth    # Trained autoencoder model\n",
        "│   └── yolo_helmet.pt     # YOLOv8 helmet detector\n",
        "└── README.md\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "La3UiG5Ow16X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile Readme.md\n",
        "\n",
        "---\n",
        "title: AI Safety Inspector\n",
        "\n",
        "colorFrom: blue\n",
        "colorTo: red\n",
        "sdk: gradio\n",
        "sdk_version: 4.29.0\n",
        "app_file: app.py\n",
        "pinned: false\n",
        "license: mit\n",
        "---\n",
        "\n",
        "#  AI Safety Inspector\n",
        "\n",
        "Detects safety hazards like missing helmets and danger zones using:\n",
        "- Unsupervised Learning (Autoencoder)\n",
        "- YOLOv8 Object Detection\n",
        "\n",
        "##  Features\n",
        "-  Anomaly detection without labels\n",
        "-  Helmet detection with bounding boxes\n",
        "\n",
        "##  How to Use\n",
        "1. Upload a construction site image\n",
        "2. Click \"Analyze\" to detect hazards\n",
        "3. Use \"Helmet Detection\" tab for precise bounding boxes\n",
        "\n",
        "Built with PyTorch, YOLOv8, and Gradio."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WUlgCkJQXZv",
        "outputId": "e9ab286a-062d-424d-c455-b93fa33518f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting Readme.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ai-safety-inspector\n",
        "%cd ai-safety-inspector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8alDbpTHAOW",
        "outputId": "065c33ef-65bf-437a-fda1-58e9acdcd84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ai-safety-inspector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iq-zFT6eDQmo",
        "outputId": "d00118ae-cca2-4c39-c27a-8d3141e0c043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "torch\n",
        "torchvision\n",
        "numpy\n",
        "scikit-learn\n",
        "gradio\n",
        "diffusers\n",
        "transformers\n",
        "accelerate\n",
        "safetensors\n",
        "Pillow\n",
        "matplotlib\n",
        "ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdO6X4ZnDhxm",
        "outputId": "0da4be6b-d66f-4901-de12-831284caee00",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 1)) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (0.21.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 3)) (2.0.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 4)) (1.6.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 5)) (5.38.1)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 6)) (0.34.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 7)) (4.53.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 8)) (1.9.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 9)) (0.5.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 10)) (11.3.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 11)) (3.10.0)\n",
            "Collecting ultralytics (from -r requirements.txt (line 12))\n",
            "  Downloading ultralytics-8.3.170-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->-r requirements.txt (line 1))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->-r requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->-r requirements.txt (line 4)) (3.6.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (4.9.0)\n",
            "Requirement already satisfied: brotli>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.116.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: gradio-client==1.11.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (1.11.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.1.2)\n",
            "Requirement already satisfied: httpx<1.0,>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.33.4)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (3.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (3.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (25.0)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (2.2.2)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.12.4)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.47.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio->-r requirements.txt (line 5)) (0.35.0)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.11.0->gradio->-r requirements.txt (line 5)) (15.0.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 6)) (8.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers->-r requirements.txt (line 6)) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 7)) (0.21.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->-r requirements.txt (line 7)) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate->-r requirements.txt (line 8)) (5.9.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->-r requirements.txt (line 11)) (2.9.0.post0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 12)) (4.12.0.88)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics->-r requirements.txt (line 12)) (9.0.0)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics->-r requirements.txt (line 12))\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 5)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 5)) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r requirements.txt (line 5)) (2025.7.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1.0,>=0.24.1->gradio->-r requirements.txt (line 5)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio->-r requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio->-r requirements.txt (line 5)) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio->-r requirements.txt (line 5)) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 5)) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio->-r requirements.txt (line 5)) (0.4.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 6)) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers->-r requirements.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->-r requirements.txt (line 6)) (3.23.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio->-r requirements.txt (line 5)) (0.1.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics-8.3.170-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.170 ultralytics-thop-2.0.14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile train_autoencoder.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#Feature Extractor (ResNet)\n",
        "resnet = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
        "resnet = nn.Sequential(*list(resnet.children())[:-1])\n",
        "resnet.eval().to(device)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, img_dir):\n",
        "        self.img_dir = img_dir\n",
        "        self.img_names = [f for f in os.listdir(img_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if len(self.img_names) == 0:\n",
        "            raise ValueError(f\"No images found in {img_dir}. Please upload images first!\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_names)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_names[idx])\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        return transform(img)\n",
        "\n",
        "#Autoencoder Model\n",
        "class ConvAutoencoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvAutoencoder, self).__init__()\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(64, 32, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 3, 3, stride=2, padding=1,output_padding=1),\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = self.decoder(x)\n",
        "        return x\n",
        "\n",
        "#Training\n",
        "def train_autoencoder(data_dir=\"data/unlabeled\", epochs=10, lr=1e-3):\n",
        "    try:\n",
        "        dataset = ImageDataset(data_dir)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "        print(\"Tip: Upload images to data/unlabeled/ using the Colab file uploader or download sample images.\")\n",
        "        return\n",
        "\n",
        "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "    model = ConvAutoencoder().to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    print(f\"Training autoencoder on {len(dataset)} images...\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            batch = batch.to(device)\n",
        "            recon = model(batch)\n",
        "            loss = criterion(recon, batch)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(dataloader):.4f}\")\n",
        "\n",
        "    os.makedirs(\"models\", exist_ok=True)\n",
        "    torch.save(model.state_dict(),\"models/autoencoder.pth\")\n",
        "    print(\"Autoencoder saved to models/autoencoder.pth\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_autoencoder()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qaUIq0V1JDP-",
        "outputId": "1d6872a0-bb54-4dd0-b6e3-f04fd2d9586d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing train_autoencoder.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile detect_anomaly.py\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torchvision.transforms as T\n",
        "from train_autoencoder import ConvAutoencoder\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ConvAutoencoder().to(device)\n",
        "model.load_state_dict(torch.load(\"models/autoencoder.pth\", map_location=device))\n",
        "model.eval()\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((224, 224)),\n",
        "    T.ToTensor(),\n",
        "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def detect_hazard(img_pil):\n",
        "    \"\"\"\n",
        "    Returns: (is_anomalous: bool, recon_error: float, reconstructed_img: PIL)\n",
        "    \"\"\"\n",
        "    img_tensor = transform(img_pil).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        recon = model(img_tensor)\n",
        "        loss_fn = torch.nn.MSELoss()\n",
        "        recon_error = loss_fn(recon, img_tensor).item()\n",
        "\n",
        "    # Convert recon to PIL\n",
        "    recon_pil = recon.cpu().squeeze(0)\n",
        "    recon_pil = T.ToPILImage()(recon_pil)\n",
        "\n",
        "    # Threshold (adjust based on validation)\n",
        "    is_anomalous = recon_error > 0.02\n",
        "\n",
        "    return is_anomalous, recon_error, recon_pil"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ql9R4iZpFLCP",
        "outputId": "00156e3a-068a-426f-d6e6-6d58a0725c8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing detect_anomaly.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile detect_helmet.py\n",
        "from ultralytics import YOLO\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "MODEL_PATH = \"models/yolo_helmet.pt\"\n",
        "\n",
        "def download_pretrained_yolo():\n",
        "    print(\"Downloading YOLOv8n for helmet detection...\")\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    model.save(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "def load_helmet_model():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(\"Model not found, downloading base YOLOv8...\")\n",
        "        download_pretrained_yolo()\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    return model\n",
        "\n",
        "def detect_helmet_in_image(img_pil, conf_threshold=0.5):\n",
        "    model = load_helmet_model()\n",
        "    results = model(img_pil, conf=conf_threshold)\n",
        "    result = results[0]\n",
        "    annotated_img = result.plot()\n",
        "    annotated_pil = Image.fromarray(annotated_img)\n",
        "\n",
        "    missing_helmets = 0\n",
        "    detections = []\n",
        "\n",
        "    for box in result.boxes:\n",
        "        cls_id = int(box.cls)\n",
        "        conf = float(box.conf)\n",
        "        label = result.names[cls_id]\n",
        "        detections.append(f\"{label}: {conf:.2f}\")\n",
        "        if \"head\" in label.lower() or \"person\" in label.lower():\n",
        "            missing_helmets += 1\n",
        "\n",
        "    return annotated_pil, missing_helmets, \", \".join(detections)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pCHLKscFyeP",
        "outputId": "006b1b98-9e50-4cb6-e6dd-425de5f21db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing detect_helmet.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile generate_hazards.py\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "os.makedirs(\"synthetic/generated_hazards\", exist_ok=True)\n",
        "\n",
        "def generate_unsafe_image(prompt=\"construction worker without hard hat, near crane, dangerous zone, realistic\", num_images=1):\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"runwayml/stable-diffusion-v1-5\", torch_dtype=torch.float16)\n",
        "    pipe = pipe.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    images = pipe(prompt, num_images_per_prompt=num_images).images\n",
        "\n",
        "    for i, img in enumerate(images):\n",
        "        path = f\"synthetic/generated_hazards/hazard_{i}.png\"\n",
        "        img.save(path)\n",
        "        print(f\"Generated: {path}\")\n",
        "\n",
        "    return images[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWLTbCbqF13V",
        "outputId": "20b99d48-9822-4664-b9eb-9e41731c6e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing generate_hazards.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile explain_alert.py\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", torch_dtype=torch.float16)\n",
        "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def explain_hazard(helmet=\"No\", zone=\"Danger\", lighting=\"Poor\"):\n",
        "    prompt = f\"\"\"\n",
        "    <|system|>\n",
        "    You are a safety officer. Explain the hazard and recommend action.\n",
        "    </s>\n",
        "    <|user|>\n",
        "    Worker helmet: {helmet}\n",
        "    Location: {zone} zone\n",
        "    Lighting: {lighting}\n",
        "    Explain the risk clearly and suggest action.\n",
        "    </s>\n",
        "    <|assistant|>\n",
        "    \"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    outputs = model.generate(**inputs, max_new_tokens=200, do_sample=True, temperature=0.7)\n",
        "    explanation = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    explanation = explanation.split(\"<|assistant|>\")[-1].strip()\n",
        "    return explanation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvEGof6zF7CS",
        "outputId": "d813e7d9-f8c2-40b3-db94-ac91becdfc1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing explain_alert.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# Import modules\n",
        "from detect_anomaly import detect_hazard\n",
        "from generate_hazards import generate_unsafe_image\n",
        "from explain_alert import explain_hazard\n",
        "from detect_helmet import detect_helmet_in_image\n",
        "\n",
        "last_result = {\"anomalous\": False, \"error\": 0.0}\n",
        "\n",
        "def analyze_image(img):\n",
        "    global last_result\n",
        "    if img is None:\n",
        "        return \"Please upload an image\", None, None\n",
        "\n",
        "    pil_img = Image.fromarray(img).convert(\"RGB\")\n",
        "    is_anomalous, error, recon = detect_hazard(pil_img)\n",
        "    last_result = {\"anomalous\": is_anomalous, \"error\": error}\n",
        "\n",
        "    alert = \"HAZARD DETECTED: No helmet or danger zone!\" if is_anomalous else \"No hazard detected.\"\n",
        "\n",
        "    explanation = explain_hazard(\n",
        "        helmet=\"No\" if is_anomalous else \"Yes\",\n",
        "        zone=\"Danger\" if is_anomalous else \"Safe\",\n",
        "        lighting=\"Normal\"\n",
        "    )\n",
        "\n",
        "    return alert, recon, explanation\n",
        "\n",
        "def create_synthetic():\n",
        "    img = generate_unsafe_image()\n",
        "    return img\n",
        "\n",
        "#Gradio Interface\n",
        "with gr.Blocks(title=\"AI Safety Inspector\") as demo:\n",
        "    gr.Markdown(\"# AI Safety Inspector\\nDetects missing helmets, danger zones using **Unsupervised + Gen AI**\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"Analyze Image\"):\n",
        "            with gr.Row():\n",
        "                input_img = gr.Image(label=\"Upload Site Photo\")\n",
        "                output_recon = gr.Image(label=\"Reconstructed (Autoencoder)\")\n",
        "            output_alert = gr.Label(label=\"Status\")\n",
        "            output_explain = gr.Textbox(label=\"AI Safety Officer Says\")\n",
        "            btn = gr.Button(\"Analyze\")\n",
        "            btn.click(analyze_image, inputs=input_img, outputs=[output_alert, output_recon, output_explain])\n",
        "\n",
        "        with gr.Tab(\"Helmet Detection (YOLOv8)\"):\n",
        "            gr.Markdown(\"Detects workers and checks if they are wearing helmets using YOLOv8.\")\n",
        "\n",
        "            with gr.Row():\n",
        "                yolo_input = gr.Image(label=\"Upload Image\")\n",
        "                yolo_output_img = gr.Image(label=\"Detected Helmets\")\n",
        "\n",
        "            yolo_output_count = gr.Number(label=\"Workers Without Helmet\")\n",
        "            yolo_output_labels = gr.Textbox(label=\"Detections\")\n",
        "\n",
        "            yolo_btn = gr.Button(\"Run Helmet Detection\")\n",
        "            yolo_btn.click(\n",
        "                detect_helmet_in_image,\n",
        "                inputs=yolo_input,\n",
        "                outputs=[yolo_output_img, yolo_output_count, yolo_output_labels]\n",
        "            )\n",
        "\n",
        "        with gr.Tab(\"Generate Synthetic Hazard (Gen AI)\"):\n",
        "            gen_output = gr.Image(label=\"Generated Unsafe Scenario\")\n",
        "            gen_btn = gr.Button(\"Generate No-Helmet Danger Scene\")\n",
        "            gen_btn.click(create_synthetic, outputs=gen_output)\n",
        "\n",
        "        with gr.Tab(\"ℹ About\"):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### How It Works\n",
        "            - Uses **autoencoder** to detect anomalies (no labels needed!)\n",
        "            - **YOLOv8** detects helmets with bounding boxes\n",
        "            - **Stable Diffusion** generates synthetic unsafe images\n",
        "            - **TinyLlama** explains alerts in natural language\n",
        "            - Runs on **Google Colab**\n",
        "            \"\"\")\n",
        "\n",
        "#Launch\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-okABbjkF86Q",
        "outputId": "905eb731-92b6-4c30-fd31-1264fe472586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p models data/unlabeled synthetic/generated_hazards"
      ],
      "metadata": {
        "id": "A-R_0dK-GyTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_urls = [\n",
        "    \"https://thumbs.dreamstime.com/b/construction-worker-without-helmet-building-site-unsafe-practice-216987654.jpg\",\n",
        "    \"https://img.freepik.com/free-photo/worker-construction-site-without-helmet_23-2149174471.jpg\",\n",
        "    \"https://ohsonline.com/articles/2014/07/01/-/media/OHS/OHS/Images/2014/07/rust.jpg\",\n",
        "    \"https://www.alertmedia.com/wp-content/uploads/2021/09/OSHA_Blog-Image_A-1536x804.jpg\",\n",
        "    \"https://www.citationcanada.com/app/uploads/2024/07/Addressing-Common-Excuses-for-Employees-Not-Wearing-PPE-at-Work-Feature.png\"\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import time\n",
        "\n",
        "print(\"Downloading sample construction images...\")\n",
        "\n",
        "for i, url in enumerate(sample_urls):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Check if it's actually an image\n",
        "        content_type = response.headers.get('content-type', '')\n",
        "        if 'image' not in content_type:\n",
        "            print(f\"Not an image: {url}\")\n",
        "            continue\n",
        "\n",
        "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        img.save(f\"data/unlabeled/sample_{i}.jpg\")\n",
        "        print(f\" Downloaded: sample_{i}.jpg\")\n",
        "        time.sleep(0.5)  # Be nice to servers\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download {url}: {str(e)[:100]}...\")\n",
        "\n",
        "print(\"Sample images added to data/unlabeled/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EwHqjvM7JLlv",
        "outputId": "09f0f667-eeb2-46a7-caf9-1c23c6d1146a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading sample construction images...\n",
            " Downloaded: sample_0.jpg\n",
            " Downloaded: sample_1.jpg\n",
            " Downloaded: sample_2.jpg\n",
            " Downloaded: sample_3.jpg\n",
            " Downloaded: sample_4.jpg\n",
            "Sample images added to data/unlabeled/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt -O models/yolo_helmet.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUTqa7BDHV5t",
        "outputId": "95edf995-21c7-4e65-967e-8a02c43076e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-30 12:17:20--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8n.pt\n",
            "Resolving github.com (github.com)... 140.82.116.3\n",
            "Connecting to github.com (github.com)|140.82.116.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://release-assets.githubusercontent.com/github-production-release-asset/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T13%3A17%3A51Z&rscd=attachment%3B+filename%3Dyolov8n.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T12%3A17%3A03Z&ske=2025-07-30T13%3A17%3A51Z&sks=b&skv=2018-11-09&sig=O1DI7a18NYBrQLwRztjwDk7VgeHWAlvQeVLxFj8573U%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg3ODE0MCwibmJmIjoxNzUzODc3ODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.0p1krVKpJu9e5cuAOr0RHiB3_6F4-GHVYVNh8Hv2crI&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-07-30 12:17:20--  https://release-assets.githubusercontent.com/github-production-release-asset/521807533/732c503e-9fcb-4a82-be7f-106baafbda15?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-07-30T13%3A17%3A51Z&rscd=attachment%3B+filename%3Dyolov8n.pt&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-07-30T12%3A17%3A03Z&ske=2025-07-30T13%3A17%3A51Z&sks=b&skv=2018-11-09&sig=O1DI7a18NYBrQLwRztjwDk7VgeHWAlvQeVLxFj8573U%3D&jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc1Mzg3ODE0MCwibmJmIjoxNzUzODc3ODQwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.0p1krVKpJu9e5cuAOr0RHiB3_6F4-GHVYVNh8Hv2crI&response-content-disposition=attachment%3B%20filename%3Dyolov8n.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6534387 (6.2M) [application/octet-stream]\n",
            "Saving to: ‘models/yolo_helmet.pt’\n",
            "\n",
            "models/yolo_helmet. 100%[===================>]   6.23M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-07-30 12:17:20 (103 MB/s) - ‘models/yolo_helmet.pt’ saved [6534387/6534387]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train_autoencoder.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYaa7D_yHaHs",
        "outputId": "f7c5b90c-eab9-4df9-e4d2-da1241dc84c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 180MB/s]\n",
            "Training autoencoder on 5 images...\n",
            "Epoch 1/10: 100% 1/1 [00:01<00:00,  1.13s/it]\n",
            "Epoch 1, Loss: 1.8946\n",
            "Epoch 2/10: 100% 1/1 [00:00<00:00, 23.13it/s]\n",
            "Epoch 2, Loss: 1.8926\n",
            "Epoch 3/10: 100% 1/1 [00:00<00:00, 25.89it/s]\n",
            "Epoch 3, Loss: 1.8896\n",
            "Epoch 4/10: 100% 1/1 [00:00<00:00, 26.05it/s]\n",
            "Epoch 4, Loss: 1.8840\n",
            "Epoch 5/10: 100% 1/1 [00:00<00:00, 25.62it/s]\n",
            "Epoch 5, Loss: 1.8736\n",
            "Epoch 6/10: 100% 1/1 [00:00<00:00, 27.36it/s]\n",
            "Epoch 6, Loss: 1.8547\n",
            "Epoch 7/10: 100% 1/1 [00:00<00:00, 26.42it/s]\n",
            "Epoch 7, Loss: 1.8222\n",
            "Epoch 8/10: 100% 1/1 [00:00<00:00, 27.21it/s]\n",
            "Epoch 8, Loss: 1.7705\n",
            "Epoch 9/10: 100% 1/1 [00:00<00:00, 26.87it/s]\n",
            "Epoch 9, Loss: 1.6948\n",
            "Epoch 10/10: 100% 1/1 [00:00<00:00, 27.38it/s]\n",
            "Epoch 10, Loss: 1.5977\n",
            "Autoencoder saved to models/autoencoder.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python app.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R22AuM0sHnWz",
        "outputId": "91c23b1d-595d-435d-aba4-e1a1b325feea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-07-26 19:54:41.882860: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1753559682.140216    1312 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1753559682.211984    1312 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "tokenizer_config.json: 1.29kB [00:00, 8.91MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 13.6MB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 44.4MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 4.44MB/s]\n",
            "config.json: 100% 608/608 [00:00<00:00, 4.78MB/s]\n",
            "model.safetensors: 100% 2.20G/2.20G [00:08<00:00, 254MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 693kB/s]\n",
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://dc8aa872802565bb03.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "\n",
            "0: 480x640 1 person, 62.1ms\n",
            "Speed: 39.6ms preprocess, 62.1ms inference, 30.5ms postprocess per image at shape (1, 3, 480, 640)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3107, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/ai-safety-inspector/app.py\", line 84, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3013, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3111, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://dc8aa872802565bb03.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vSwSd0wibxE9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}